{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1bb3e06e8034ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Experiment Setup\n",
    "\n",
    "## Audio Corpus\n",
    "We will be using an English excerpt from the IMDA National Speech Corpus (NSC). The aim of this transcription, and subsequent minutes generation, is to test the latest `large-v3` Whisper model on the __Singlish__ Accent.\n",
    "\n",
    "We will be testing it on the sample ID `3030` from the `NSC` dataset. This sample contains a conversation between a Singaporean Male and Singaporean Female. The exact lexicon used in the conversation recording includes Singlish phrases i.e. 'aiya', 'leh', 'lah'. We will be testing the model's ability to transcribe these phrases accurately. NSC provides:\n",
    "- Speaker 1's Audio\n",
    "- Speaker 2's Audio\n",
    "- Overall Audio\n",
    "\n",
    "## Transcription Corpus\n",
    "The NSC also provides a transcription of the audio corpus. We will be using this to compare the model's transcription accuracy. NSC provides:\n",
    "- Speaker 1's Transcription\n",
    "- Speaker 2's Transcription\n",
    "\n",
    "This will greatly aid our efforts when comparing the efficacy of the text-level speaker diarization later on. Do note that the transcription is given using the TextGrid format. From my initial analysis, it seems to conform with some variation of SSML. \n",
    "\n",
    "## Model\n",
    "We will be using the latest `large-v3` model offered by OpenAI, running it on the CPU (due to lack of CUDA GPU on my current system), and analysing the transcription accuracy. If we deem that it is up to standard, then we can proceed to __Speaker Diarization__. Else, we may put plans in place to retrain the model on the Singlish Accent. As mentioned above, we are currently using the IMDA NSC as our audio corpus, and it's roughly 890Gb of data. We will be using a small subset of this data for the initial testing.\n",
    "\n",
    "## Future Plans\n",
    "If the model is up to standard, we will proceed to __Speaker Diarization__ and __Minutes Generation__."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (1.14.2)\r\n",
      "Requirement already satisfied: python-dotenv in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: faster-whisper in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (4.3.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (2.6.4)\r\n",
      "Requirement already satisfied: sniffio in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from openai) (4.10.0)\r\n",
      "Requirement already satisfied: av==11.* in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from faster-whisper) (11.0.0)\r\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from faster-whisper) (4.1.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from faster-whisper) (0.21.4)\r\n",
      "Requirement already satisfied: tokenizers<0.16,>=0.13 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from faster-whisper) (0.15.2)\r\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from faster-whisper) (1.17.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: setuptools in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (68.2.2)\r\n",
      "Requirement already satisfied: numpy in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\r\n",
      "Requirement already satisfied: certifi in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.9.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster-whisper) (2024.3.1)\r\n",
      "Requirement already satisfied: requests in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\r\n",
      "Requirement already satisfied: coloredlogs in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.7)\r\n",
      "Requirement already satisfied: protobuf in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.26.0)\r\n",
      "Requirement already satisfied: sympy in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.2.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/justin/miniconda3/envs/minutes_gpt/lib/python3.10/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv faster-whisper"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:16:57.198129Z",
     "start_time": "2024-07-05T14:16:55.718564Z"
    }
   },
   "id": "1fa373363d56fb48",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "DEPLOYMENT = dotenv.get_key(dotenv.find_dotenv(), \"DEPLOYMENT\")\n",
    "ENDPOINT = dotenv.get_key(dotenv.find_dotenv(), \"AZURE_OPENAI_ENDPOINT\")\n",
    "KEY = dotenv.get_key(dotenv.find_dotenv(), \"AZURE_OPENAI_KEY\")\n",
    "VERSION = dotenv.get_key(dotenv.find_dotenv(), \"AZURE_OPENAI_VERSION\")\n",
    "HF_ACCESS_KEY = dotenv.get_key(dotenv.find_dotenv(),\"HF_ACCESS_KEY\")\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "\t# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
    "\tapi_version=VERSION,\n",
    "\t# https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
    "\tazure_endpoint=ENDPOINT,\n",
    "\tapi_key=KEY\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:02.075377Z",
     "start_time": "2024-07-05T16:02:01.431630Z"
    }
   },
   "id": "232f608d30239f2e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578ebd4beb836880",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:26.834565Z",
     "start_time": "2024-07-05T16:02:02.882374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Whisper(\n  (encoder): AudioEncoder(\n    (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n    (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n    (blocks): ModuleList(\n      (0-23): 24 x ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=1024, out_features=1024, bias=True)\n          (key): Linear(in_features=1024, out_features=1024, bias=False)\n          (value): Linear(in_features=1024, out_features=1024, bias=True)\n          (out): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (decoder): TextDecoder(\n    (token_embedding): Embedding(51865, 1024)\n    (blocks): ModuleList(\n      (0-23): 24 x ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=1024, out_features=1024, bias=True)\n          (key): Linear(in_features=1024, out_features=1024, bias=False)\n          (value): Linear(in_features=1024, out_features=1024, bias=True)\n          (out): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=1024, out_features=1024, bias=True)\n          (key): Linear(in_features=1024, out_features=1024, bias=False)\n          (value): Linear(in_features=1024, out_features=1024, bias=True)\n          (out): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "torch.cuda.init()\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31476ebaa0ecca6a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Meeting-Specific Prompts and Phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5f758dc67739c9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:26.852668Z",
     "start_time": "2024-07-05T16:02:26.841585Z"
    }
   },
   "outputs": [],
   "source": [
    "# general = ['Air Traffic Control communications','1','2','3','4','5','6','7','8','9','0','90','180','270','360']\n",
    "# nato = [\n",
    "# \t'Alpha', 'Bravo', 'Charlie', 'Delta', 'Echo', 'Foxtrot', 'Golf',\n",
    "# \t'Hotel', 'India', 'Juliett', 'Kilo', 'Lima', 'Mike', 'November',\n",
    "# \t'Oscar', 'Papa', 'Quebec', 'Romeo', 'Sierra', 'Tango', 'Uniform',\n",
    "# \t'Victor', 'Whiskey', 'Xray', 'Yankee', 'Zulu'\n",
    "# ]\n",
    "# \n",
    "# atc_words = [\n",
    "#     \"acknowledge\", \"affirmative\", \"altitude\", \"approach\", \"apron\", \"arrival\",\n",
    "#     \"bandbox\", \"base\", \"bearing\", \"cleared\", \"climb\", \"contact\", \"control\",\n",
    "#     \"crosswind\", \"cruise\", \"descend\", \"departure\", \"direct\", \"disregard\",\n",
    "#     \"downwind\", \"estimate\", \"final\", \"flight\", \"frequency\", \"go around\",\n",
    "#     \"heading\", \"hold\", \"identified\", \"immediate\", \"information\", \"instruct\",\n",
    "#     \"intentions\", \"land\", \"level\", \"maintain\", \"mayday\", \"message\", \"missed\",\n",
    "#     \"navigation\", \"negative\", \"obstruction\", \"option\", \"orbit\", \"pan-pan\",\n",
    "#     \"pattern\", \"position\", \"proceed\", \"radar\", \"readback\", \"received\",\n",
    "#     \"report\", \"request\", \"required\", \"runway\", \"squawk\", \"standby\", \"takeoff\",\n",
    "#     \"taxi\", \"threshold\", \"traffic\", \"transit\", \"turn\", \"vector\", \"visual\",\n",
    "#     \"waypoint\", \"weather\", \"wilco\", \"wind\", \"with you\", \"speed\",\n",
    "#     \"heavy\", \"light\", \"medium\", \"emergency\", \"fuel\", \"identifier\",\n",
    "#     \"limit\", \"monitor\", \"notice\", \"operation\", \"permission\", \"relief\",\n",
    "#     \"route\", \"signal\", \"stand\", \"system\", \"terminal\", \"test\", \"track\",\n",
    "#     \"understand\", \"verify\", \"vertical\", \"warning\", \"zone\", \"no\", \"yes\", \"unable\",\n",
    "#     \"clearance\", \"conflict\", \"coordination\", \"cumulonimbus\", \"deviation\", \"enroute\",\n",
    "#     \"fix\", \"glideslope\", \"handoff\", \"holding\", \"IFR\", \"jetstream\", \"knots\",\n",
    "#     \"localizer\", \"METAR\", \"NOTAM\", \"overfly\", \"pilot\", \"QNH\", \"radial\",\n",
    "#     \"sector\", \"SID\", \"STAR\", \"tailwind\", \"transition\", \"turbulence\", \"uncontrolled\",\n",
    "#     \"VFR\", \"wake turbulence\", \"X-wind\", \"yaw\", \"Zulu time\", \"airspace\",\n",
    "#     \"briefing\", \"checkpoint\", \"elevation\", \"FL\",\n",
    "#     \"ground control\", \"hazard\", \"ILS\", \"jetway\", \"kilo\", \"logbook\", \"missed approach\",\n",
    "#     \"nautical mile\", \"offset\", \"profile\", \"quadrant\", \"RVR\",\n",
    "#     \"static\", \"touchdown\", \"upwind\", \"variable\", \"wingtip\", \"Yankee\", \"zoom climb\",\n",
    "#     \"airspeed\", \"backtrack\", \"ETOPS\", \"gate\", \"holding pattern\", \n",
    "#     \"jumpseat\", \"minimums\", \"pushback\", \"RNAV\", \"slot time\", \"taxiway\", \"TCAS\",\n",
    "#     \"wind shear\", \"zero fuel weight\", \"ETA\",\n",
    "#     \"flight deck\", \"ground proximity warning system\", \"jet route\",\n",
    "#     \"landing clearance\", \"Mach number\", \"NDB\", \"obstacle clearance\",\n",
    "#     \"PAPI\", \"QFE\", \"radar contact\",\n",
    "#     'ATC', 'Pilot', 'Call sign', 'Altitude', 'Heading', 'Speed', 'Climb to', 'Descend to',\n",
    "#     'Maintain', 'Tower', 'Ground', 'Runway', 'Taxi', 'Takeoff', 'Landing',\n",
    "#     'Flight level', 'Traffic', 'Hold short', 'Cleared for',\n",
    "#     'Roger', 'Visibility', 'Weather', 'Wind', 'Gusts',\n",
    "#     'Icing conditions', 'Deicing', 'VFR', 'IFR', 'No-fly zone',\n",
    "#     'Restricted airspace', 'Flight path', 'Direct route', 'Vector', 'Frequency change',\n",
    "#     'Final approach', 'Initial climb to', 'Contact approach', 'FIR', 'Control zone', 'TMA',\n",
    "#     'Missed approach', 'Minimum safe altitude', 'Transponder',\n",
    "#     'Reduce speed to', 'Increase speed to',\n",
    "#     'Flight conditions', 'Clear of conflict', 'Resume own navigation', 'Request altitude change',\n",
    "#     'Request route change', 'Flight visibility', 'Ceiling', 'Severe weather', 'Convective SIGMET',\n",
    "#     'AIRMET', 'QNH', 'QFE', 'Transition altitude', 'Transition level',\n",
    "#     'NOSIG', 'TFR', 'Special use airspace',\n",
    "#     'MOA', 'IAP', 'Visual approach',\n",
    "#     'NDB', 'VOR',\n",
    "#     'ATIS', 'Engine start clearance',\n",
    "#     'Line up and wait', 'Unicom', 'Cross runway', 'Departure frequency',\n",
    "#     'Arrival frequency', 'Go-ahead', 'Hold position', 'Check gear down',\n",
    "#     'Touch and go', 'Circuit pattern', 'Climb via SID',\n",
    "#     'Descend via STAR', 'Speed restriction', 'Flight following', 'Radar service terminated', 'Squawk VFR',\n",
    "#     'Change to advisory frequency', 'Report passing altitude', 'Report position',\n",
    "#     'ATD', 'Block altitude', 'Cruise climb', 'Direct to', 'Execute missed approach',\n",
    "#     'In-flight refueling', 'Joining instructions', 'Lost communications', 'MEA', 'Next waypoint', 'OCH',\n",
    "#     'Procedure turn', 'Radar vectoring', 'Radio failure', 'Short final', 'Standard rate turn',\n",
    "#     'TRSA', 'Undershoot', 'VMC',\n",
    "#     'Wide-body aircraft', 'Yaw damper', 'Zulu time conversion', 'RNAV',\n",
    "#     'RNP', 'Barometric pressure', 'Control tower handover', 'Datalink communication',\n",
    "#     'ELT', 'FDR', 'GCI',\n",
    "#     'Hydraulic failure', 'IMC', 'Knock-it-off',\n",
    "#     'LVO', 'MAP', 'NAVAIDS',\n",
    "#     'Oxygen mask deployment', 'PAR', 'QRA',\n",
    "#     'Runway incursion', 'SAR', 'Tail strike', 'Upwind leg', 'Vertical speed',\n",
    "#     'Wake turbulence category', 'X-ray cockpit security', 'Yield to incoming aircraft', 'Zero visibility takeoff','good day'\n",
    "# ]\n",
    "# \n",
    "# \n",
    "# collated_list = general + nato + atc_words \n",
    "\n",
    "\n",
    "general = ['Singaporean Singlish Meeting Transcription Recording']\n",
    "\n",
    "singlish_phrases = [\n",
    "\t\"ah\", \"lah\", \"aiya\", \"leh\", \"aiyo\", \"can or not\", \"on the ball\", \"makan session\", \"pow-wow\",\n",
    "\t\"kiasu\", \"bo jio\", \"sian\", \"shiok\", \"jialat\", 'saigang',\n",
    "\t\"talk cock\", \"wayang\", \"kena\", \"chop-chop\", \"steady\",\n",
    "\t\"own time own target (OTOT)\", \"kopi talk\", \"catch up\", \"brainstorm\", \"align\",\n",
    "\t\"lobang\", \"paiseh\", \"action\", \"agaration\", \"angkat bola\",\n",
    "\t\"bao ga liao\", \"buay pai\", \"cheem\", \"chio\", \"garang\",\n",
    "\t\"goondu\", \"kaypoh\", \"leh\", \"lor\", \"nia\",\n",
    "\t\"one corner\", \"open table\", \"pai seh\", \"relak one corner\", \"sabo\",\n",
    "\t\"sai kang\", \"shiok\", \"siam\", \"sikit-sikit\", \"suay\",\n",
    "\t\"tabao\", \"talk shop\", \"tan tio\", \"up lorry\", \"wa kau\"\n",
    "]\n",
    "\n",
    "singlish_business_phrases = [\n",
    "\t\"lah\", \"can or not?\", \"on the ball\", \"kiasu\", \"shiok\",\n",
    "\t\"talk cock\", \"steady pom pi pi\", \"own time own target\", \"bo jio\", \"catch no ball\",\n",
    "\t\"chiong\", \"chop chop\", \"die die must do\", \"eat snake\", \"gostan\",\n",
    "\t\"jialat\", \"kaypoh\", \"leh\", \"lor\", \"makan\",\n",
    "\t\"nabei\", \"paiseh\", \"sabo\", \"sian\", \"suay\",\n",
    "\t\"walao eh\", \"wayang\", \"win already lor\", \"yaya papaya\", \"zi high\",\n",
    "\t\"send it\", \"check back next week\", \"let’s touch base on this\", \"circle back on that\", \"park this for now\",\n",
    "\t\"align our ducks\", \"low key\", \"see how\", \"can make it\", \"noted with thanks\",\n",
    "\t\"bo bian\", \"anyhow\", \"confirm plus chop\", \"got chance\", \"mai tu liao\",\n",
    "\t\"double confirm\", \"one shot\", \"over already\", \"swee\", \"talk later\"\n",
    "]\n",
    "\n",
    "collated_list = general + singlish_phrases + singlish_business_phrases \n",
    "\n",
    "\n",
    "collated_list_string = ' '.join(collated_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a11d8810f95ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Our Experiment\n",
    "## Label-Aware Strided Adaptive Diarization\n",
    "\n",
    "In this experiment, we implement a strategy to update chunks with strides, incorporating both past and future context, and enhancing the diarization process by making the model aware of speaker labels from previous chunks.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "We split the transcribed text into `x` number of chunks, and for each chunk, we also add a stride of `a` behind and in front of the chunk. This approach allows us to capture the conversation context more effectively and thus provide a more accurate diarization.\n",
    "\n",
    "#### Chunking and Stride\n",
    "\n",
    "1. **Chunk Size and Number of Chunks:**\n",
    "\n",
    "\\begin{equation}\n",
    "N = \\text{length of list}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "c = \\text{chunk size}, \\, a = \\text{stride length}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "x = \\left\\lceil \\frac{N}{c} \\right\\rceil, \\, \\text{number of chunks}\n",
    "\\end{equation}\n",
    "\n",
    "2. **Initial Chunk Definition:**\n",
    "\n",
    "\\begin{equation}\n",
    "S_i = i \\cdot c, \\, E_i = \\min((i+1) \\cdot c - 1, N-1), \\, 0 \\leq i < x\n",
    "\\end{equation}\n",
    "\n",
    "3. **Stride Modifications:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{For } i = 1 \\text{ to } x-2:\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Prepend } \\text{sort}(\\text{last } a \\text{ elements of } \\text{chunk}_{i-1}, \\text{desc}) \\text{ to } \\text{chunk}_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Append } \\text{sort}(\\text{first } a \\text{ elements of } \\text{chunk}_{i+1}) \\text{ to } \\text{chunk}_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{For } i = 0 \\text{ and } i = x-1, \\text{ chunks remain unchanged.}\n",
    "\\end{equation}\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider the initial chunked list and its updated version with a stride \\(a=2\\):\n",
    "\n",
    "#### Initial chunked list:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "[0, 1, 2, 3, 4, 5] \\\\\n",
    "[6, 7, 8, 9, 10, 11] \\\\\n",
    "[12, 13, 14, 15, 16, 17] \\\\\n",
    "[18, 19, 20, 21]\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "#### Updated with stride:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "[0, 1, 2, 3, 4, 5] \\\\\n",
    "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13] \\\\\n",
    "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] \\\\\n",
    "[16, 17, 18, 19, 20, 21]\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "\n",
    "### Diarization Process\n",
    "\n",
    "Each chunk, upon submission, will carry the respective speaker labels for the preceding \\(a\\) elements, enriching the context for improved accuracy.\n",
    "\n",
    "**Backstride:** Elements from the past stride\n",
    "\n",
    "**Forwardstride:** Elements from the future stride\n",
    "\n",
    "Starting with chunk 1 (where 0 ≤ i < x), specifically the second chunk:\n",
    "\n",
    "\n",
    "\\begin{bmatrix}\n",
    "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "The last \\(a=2\\) speaker labels from the `backstride` will be incorporated into the context. \n",
    "\n",
    "If, for instance, the speaker labels for elements \\(4\\) and \\(5\\) are `Speaker 1`, this provides the Language Model (LLM) with valuable historical context from the previous diarization session, hypothetically enabling more precise diarization results.\n",
    "\n",
    "### Final Formulation\n",
    "\n",
    "#### Initial Chunks:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{chunks}_i = [i \\cdot c \\text{ to } (i+1) \\cdot c - 1]\n",
    "\\end{equation}\n",
    "\n",
    "#### Stride Modifications:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{chunks}_i = [(\\text{chunks}_{i-1} \\text{ last } a \\text{ elements}) + \\text{chunks}_i + (\\text{chunks}_{i+1} \\text{ first } a \\text{ elements})]\n",
    "\\end{equation}\n",
    "\n",
    "#### Label-Aware Diarization:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Speaker Labels for chunk}_i = \\text{LLM}( \\text{chunks}_i \\text{ with context from previous labels} )\n",
    "\\end{equation}\n",
    "\n",
    "This approach enriches the information available for each chunk, aiding the Language Model in generating more accurate diarization outcomes by leveraging historical speaker labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69de3f991d30f8f9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:27.275597Z",
     "start_time": "2024-07-05T16:02:26.854370Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup code\n",
    "# Specify the directory path\n",
    "transcriptions_dir = \"./transcriptions\"\n",
    "audio_file = '../content/meeting/daily_ketchup.wav'\n",
    "specific_filename = \"daily_ketchup.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:27.282485Z",
     "start_time": "2024-07-05T16:02:27.278021Z"
    }
   },
   "id": "c67187ac9a28d69f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[91mNo matching transcription files found.\u001B[0m\n",
      "[00:00.000 --> 00:06.880]  After a few weeks, he didn't see any recovery, muscle recovery.\n",
      "[00:08.160 --> 00:13.280]  So he said, very likely that I will have to be paralysed for life.\n",
      "[00:13.280 --> 00:16.320]  What goes through your head though, when this information is given to a man?\n",
      "[00:16.320 --> 00:20.720]  Initially, there was a lot of denial that this actually was going to happen.\n",
      "[00:20.720 --> 00:22.400]  All my friends are riders.\n",
      "[00:22.400 --> 00:27.920]  All of us have been through accidents, even some major ones.\n",
      "[00:27.920 --> 00:32.960]  My friend banged his body into a tree and his rib punctured his lungs.\n",
      "[00:32.960 --> 00:34.800]  It was quite bad.\n",
      "[00:34.800 --> 00:39.280]  But after a few months, he still managed to recover and he's back on his feet.\n",
      "[00:39.280 --> 00:42.800]  So how long did it take for you to be discharged from the hospital?\n",
      "[00:42.800 --> 00:46.080]  I was in hospital for a total of about six months.\n",
      "[00:46.080 --> 00:46.880]  Months?\n",
      "[00:46.880 --> 00:50.400]  One month in the ICU, one month in high dependency,\n",
      "[00:50.400 --> 00:55.920]  and then just one month in a normal ward before they had space in the rehab.\n",
      "[00:55.920 --> 01:03.280]  Actually, what is physiotherapy?\n",
      "[01:03.280 --> 01:04.320]  Just exercises.\n",
      "[01:05.520 --> 01:08.880]  Because I still have my deltoids and my biceps,\n",
      "[01:08.880 --> 01:14.400]  but my triceps are paralysed and I have only wrist extension.\n",
      "[01:14.400 --> 01:21.360]  So I can move my wrist this way, but if I flip my hand around, I can't move my wrist.\n",
      "[01:22.400 --> 01:23.040]  No way!\n",
      "[01:23.040 --> 01:23.360]  Wow!\n",
      "[01:23.360 --> 01:24.160]  Oh, I see, I see.\n",
      "[01:24.160 --> 01:24.960]  Oh!\n",
      "[01:24.960 --> 01:29.680]  So in terms of what you can do with your limbs, what can you do?\n",
      "[01:30.240 --> 01:30.800]  What can I do?\n",
      "[01:33.040 --> 01:35.680]  Right now, I can push my own chair, but not very well.\n",
      "[01:35.680 --> 01:38.080]  It's like maybe on a flat surface, it's fine.\n",
      "[01:38.720 --> 01:42.480]  Once there's a bit of a slope or unevenness, then I struggle a bit.\n",
      "[01:42.480 --> 01:45.840]  So you can use your hands, it's just that the strength is not there.\n",
      "[01:45.840 --> 01:49.600]  I can use my arms, but my fingers are paralysed.\n",
      "[01:50.240 --> 01:52.160]  So I can't really pick things up.\n",
      "[01:52.160 --> 01:54.560]  Like if I drop my phone on the floor, I can't pick it up.\n",
      "[01:54.560 --> 01:54.800]  Oh!\n",
      "\u001B[92mTranscription completed and saved at ./transcriptions/daily_ketchup.json.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(transcriptions_dir):\n",
    "    # If the directory does not exist, create it\n",
    "    os.makedirs(transcriptions_dir)\n",
    "\n",
    "def find_latest_transcription(directory, specific_filename):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename == specific_filename:\n",
    "            return filename\n",
    "    return None\n",
    "\n",
    "# Attempt to find the specific transcription file\n",
    "latest_transcription_file = find_latest_transcription(transcriptions_dir, specific_filename)\n",
    "\n",
    "if latest_transcription_file:\n",
    "    # Full path for the latest file including the directory\n",
    "    file_path = os.path.join(transcriptions_dir, latest_transcription_file)\n",
    "    # Extract the filename without the extension\n",
    "    file_name, _ = os.path.splitext(latest_transcription_file)\n",
    "    try:\n",
    "        with open(file_path, \"r\") as stored_result:\n",
    "            # If the file exists and is opened successfully, read the content\n",
    "            result = json.load(stored_result)\n",
    "        print('\\033[92mTranscription located:\\033[0m')\n",
    "        # Extract and print the first 5 sentences\n",
    "        segments = result.get('segments', [])\n",
    "        for segment in segments[:5]:\n",
    "            start_time = round(float(segment['start']),2)\n",
    "            end_time = round(float(segment['end']),2)\n",
    "            text = segment['text']\n",
    "            print(f'[{start_time}:{end_time}] -> {text}')\n",
    "        print('...')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found, although it was expected to exist.\")\n",
    "else:\n",
    "    # No transcription file matching the pattern was found\n",
    "    print('\\033[91mNo matching transcription files found.\\033[0m')\n",
    "    # If the file does not exist, execute the transcription process and create the file\n",
    "    temp_result = model.transcribe(audio_file, verbose=True, language=\"en\", prompt=collated_list_string)\n",
    "    file_path = os.path.join(transcriptions_dir, specific_filename)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(temp_result, f)\n",
    "    result = temp_result\n",
    "    # Extract the filename without the extension\n",
    "    file_name, _ = os.path.splitext(os.path.basename(file_path))\n",
    "    print(f'\\033[92mTranscription completed and saved at {file_path}.\\033[0m')\n",
    "\n",
    "per_line = []\n",
    "for segment in result['segments']:\n",
    "    text_to_append = segment['text']\n",
    "    text_to_append = text_to_append[1:]\n",
    "    per_line.append(text_to_append)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:02:45.361848Z",
     "start_time": "2024-07-05T16:02:27.284676Z"
    }
   },
   "id": "4580682177c43e1c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "33"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(per_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:05:32.621470Z",
     "start_time": "2024-07-05T16:05:32.617663Z"
    }
   },
   "id": "cd119b6f2dc87f2",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Number of Chunks: 9\n",
      "Optimal Stride: 1\n",
      "Forced Stride: 2\n"
     ]
    }
   ],
   "source": [
    "# Initialization code for strided_chunks and strided_chunk_indices\n",
    "STRIDE = 2\n",
    "TOTAL_NUMBER_OF_LINES = len(per_line)\n",
    "DESIRED_CHUNK_SIZE = 4\n",
    "\n",
    "def calculate_number_of_chunks_with_stride(total_lines, chunk_size, stride):\n",
    "    effective_chunk_size = chunk_size + stride - 1  # Adjust chunk size to account for stride\n",
    "    number_of_chunks = (total_lines + effective_chunk_size - 1) // effective_chunk_size\n",
    "    return number_of_chunks\n",
    "\n",
    "def find_optimal_chunks(total_lines, desired_chunk_size, max_stride):\n",
    "    # Iterate through stride values from max_stride down to 1\n",
    "    for stride in range(max_stride, 0, -1):\n",
    "        number_of_chunks = calculate_number_of_chunks_with_stride(total_lines, desired_chunk_size, stride)\n",
    "        # Check if the total coverage with the current number of chunks and chunk size is sufficient\n",
    "        if number_of_chunks * desired_chunk_size >= total_lines:\n",
    "            return number_of_chunks, stride\n",
    "    return -1, -1  # Return an error if no suitable chunk and stride combination is found\n",
    "\n",
    "NUMBER_OF_CHUNKS, STRIDE = find_optimal_chunks(TOTAL_NUMBER_OF_LINES, DESIRED_CHUNK_SIZE, STRIDE)\n",
    "print('Optimal Number of Chunks:', NUMBER_OF_CHUNKS)\n",
    "print('Optimal Stride:',STRIDE)\n",
    "# but i prefer for stride to be 2 as it retains more history so...\n",
    "STRIDE = 2\n",
    "print('Forced Stride:', 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:10:30.122895Z",
     "start_time": "2024-07-05T16:10:30.119108Z"
    }
   },
   "id": "9e25bf78854b1b5d",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user message: Here is the list of sentences: \n",
      "[\"After a few weeks, he didn't see any recovery, muscle recovery.\", 'So he said, very likely that I will have to be paralysed for life.', 'What goes through your head though, when this information is given to a man?', 'Initially, there was a lot of denial that this actually was going to happen.', 'All my friends are riders.']. \n",
      "There are 5 exchanges. You will diarize ALL the sentences in the list. You WILL ensure that you label ALL 5 lines. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'Initially, there was a lot of denial that this actually was going to happen.': 'Speaker 3', 'All my friends are riders.': 'Speaker 4'} \n",
      " Here is the list of sentences:\n",
      "['Initially, there was a lot of denial that this actually was going to happen.', 'All my friends are riders.', 'All of us have been through accidents, even some major ones.', 'My friend banged his body into a tree and his rib punctured his lungs.', 'It was quite bad.', \"But after a few months, he still managed to recover and he's back on his feet.\"]\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'It was quite bad.': 'Speaker 4', \"But after a few months, he still managed to recover and he's back on his feet.\": 'Speaker 4'} \n",
      " Here is the list of sentences:\n",
      "['It was quite bad.', \"But after a few months, he still managed to recover and he's back on his feet.\", 'So how long did it take for you to be discharged from the hospital?', 'I was in hospital for a total of about six months.', 'Months?', 'One month in the ICU, one month in high dependency,']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'Months?': 'Speaker 2', 'One month in the ICU, one month in high dependency,': 'Speaker 4'} \n",
      " Here is the list of sentences:\n",
      "['Months?', 'One month in the ICU, one month in high dependency,', 'and then just one month in a normal ward before they had space in the rehab.', 'Actually, what is physiotherapy?', 'Just exercises.', 'Because I still have my deltoids and my biceps,']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'Just exercises.': 'Speaker 3', 'Because I still have my deltoids and my biceps,': 'Speaker 2'} \n",
      " Here is the list of sentences:\n",
      "['Just exercises.', 'Because I still have my deltoids and my biceps,', 'but my triceps are paralysed and I have only wrist extension.', \"So I can move my wrist this way, but if I flip my hand around, I can't move my wrist.\", 'No way!', 'Wow!']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'No way!': 'Speaker 4', 'Wow!': 'Speaker 1'} \n",
      " Here is the list of sentences:\n",
      "['No way!', 'Wow!', 'Oh, I see, I see.', 'Oh!', 'So in terms of what you can do with your limbs, what can you do?', 'What can I do?']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{'So in terms of what you can do with your limbs, what can you do?': 'Speaker 1', 'What can I do?': 'Speaker 4'} \n",
      " Here is the list of sentences:\n",
      "['So in terms of what you can do with your limbs, what can you do?', 'What can I do?', 'Right now, I can push my own chair, but not very well.', \"It's like maybe on a flat surface, it's fine.\", \"Once there's a bit of a slope or unevenness, then I struggle a bit.\", \"So you can use your hands, it's just that the strength is not there.\"]\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{\"Once there's a bit of a slope or unevenness, then I struggle a bit.\": 'Speaker 4', \"So you can use your hands, it's just that the strength is not there.\": 'Speaker 1'} \n",
      " Here is the list of sentences:\n",
      "[\"Once there's a bit of a slope or unevenness, then I struggle a bit.\", \"So you can use your hands, it's just that the strength is not there.\", 'I can use my arms, but my fingers are paralysed.', \"So I can't really pick things up.\", \"Like if I drop my phone on the floor, I can't pick it up.\", 'Oh!']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 6 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "user message: Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\n",
      "{\"Like if I drop my phone on the floor, I can't pick it up.\": 'Speaker 4', 'Oh!': 'Speaker 1'} \n",
      " Here is the list of sentences:\n",
      "[\"Like if I drop my phone on the floor, I can't pick it up.\", 'Oh!']\n",
      "Note that this contains the previous exchanges as well. I MUST RECEIVE ALL 2 exchanges. JUST RETURN ME THE LIST.\n",
      "\n",
      "[['Speaker 1', 'Speaker 1', 'Speaker 2', 'Speaker 3', 'Speaker 4'], ['Speaker 3', 'Speaker 4', 'Speaker 4', 'Speaker 4', 'Speaker 4', 'Speaker 4'], ['Speaker 4', 'Speaker 4', 'Speaker 1', 'Speaker 4', 'Speaker 2', 'Speaker 4'], ['Speaker 2', 'Speaker 4', 'Speaker 4', 'Speaker 1', 'Speaker 3', 'Speaker 2'], ['Speaker 3', 'Speaker 2', 'Speaker 2', 'Speaker 2', 'Speaker 4', 'Speaker 1'], ['Speaker 4', 'Speaker 1', 'Speaker 2', 'Speaker 3', 'Speaker 1', 'Speaker 4'], ['Speaker 1', 'Speaker 4', 'Speaker 4', 'Speaker 4', 'Speaker 4', 'Speaker 1'], ['Speaker 4', 'Speaker 1', 'Speaker 4', 'Speaker 4', 'Speaker 4', 'Speaker 1'], ['Speaker 4', 'Speaker 1']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                             original strided_chunk_0  \\\n0   After a few weeks, he didn't see any recovery,...       Speaker 1   \n1   So he said, very likely that I will have to be...       Speaker 1   \n2   What goes through your head though, when this ...       Speaker 2   \n3   Initially, there was a lot of denial that this...       Speaker 3   \n4                          All my friends are riders.       Speaker 4   \n5   All of us have been through accidents, even so...             nan   \n6   My friend banged his body into a tree and his ...             nan   \n7                                   It was quite bad.             nan   \n8   But after a few months, he still managed to re...             nan   \n9   So how long did it take for you to be discharg...             nan   \n10  I was in hospital for a total of about six mon...             nan   \n11                                            Months?             nan   \n12  One month in the ICU, one month in high depend...             nan   \n13  and then just one month in a normal ward befor...             nan   \n14                   Actually, what is physiotherapy?             nan   \n15                                    Just exercises.             nan   \n16    Because I still have my deltoids and my biceps,             nan   \n17  but my triceps are paralysed and I have only w...             nan   \n18  So I can move my wrist this way, but if I flip...             nan   \n19                                            No way!             nan   \n20                                               Wow!             nan   \n21                                  Oh, I see, I see.             nan   \n22                                                Oh!             nan   \n23  So in terms of what you can do with your limbs...             nan   \n24                                     What can I do?             nan   \n25  Right now, I can push my own chair, but not ve...             nan   \n26      It's like maybe on a flat surface, it's fine.             nan   \n27  Once there's a bit of a slope or unevenness, t...             nan   \n28  So you can use your hands, it's just that the ...             nan   \n29   I can use my arms, but my fingers are paralysed.             nan   \n30                  So I can't really pick things up.             nan   \n31  Like if I drop my phone on the floor, I can't ...             nan   \n32                                                Oh!             nan   \n\n   strided_chunk_1 strided_chunk_2 strided_chunk_3 strided_chunk_4  \\\n0              nan             nan             nan             nan   \n1              nan             nan             nan             nan   \n2              nan             nan             nan             nan   \n3        Speaker 3             nan             nan             nan   \n4        Speaker 4             nan             nan             nan   \n5        Speaker 4             nan             nan             nan   \n6        Speaker 4             nan             nan             nan   \n7        Speaker 4       Speaker 4             nan             nan   \n8        Speaker 4       Speaker 4             nan             nan   \n9              nan       Speaker 1             nan             nan   \n10             nan       Speaker 4             nan             nan   \n11             nan       Speaker 2       Speaker 2             nan   \n12             nan       Speaker 4       Speaker 4             nan   \n13             nan             nan       Speaker 4             nan   \n14             nan             nan       Speaker 1             nan   \n15             nan             nan       Speaker 3       Speaker 3   \n16             nan             nan       Speaker 2       Speaker 2   \n17             nan             nan             nan       Speaker 2   \n18             nan             nan             nan       Speaker 2   \n19             nan             nan             nan       Speaker 4   \n20             nan             nan             nan       Speaker 1   \n21             nan             nan             nan             nan   \n22             nan             nan             nan             nan   \n23             nan             nan             nan             nan   \n24             nan             nan             nan             nan   \n25             nan             nan             nan             nan   \n26             nan             nan             nan             nan   \n27             nan             nan             nan             nan   \n28             nan             nan             nan             nan   \n29             nan             nan             nan             nan   \n30             nan             nan             nan             nan   \n31             nan             nan             nan             nan   \n32             nan             nan             nan             nan   \n\n   strided_chunk_5 strided_chunk_6 strided_chunk_7 strided_chunk_8  \n0              nan             nan             nan             nan  \n1              nan             nan             nan             nan  \n2              nan             nan             nan             nan  \n3              nan             nan             nan             nan  \n4              nan             nan             nan             nan  \n5              nan             nan             nan             nan  \n6              nan             nan             nan             nan  \n7              nan             nan             nan             nan  \n8              nan             nan             nan             nan  \n9              nan             nan             nan             nan  \n10             nan             nan             nan             nan  \n11             nan             nan             nan             nan  \n12             nan             nan             nan             nan  \n13             nan             nan             nan             nan  \n14             nan             nan             nan             nan  \n15             nan             nan             nan             nan  \n16             nan             nan             nan             nan  \n17             nan             nan             nan             nan  \n18             nan             nan             nan             nan  \n19       Speaker 4             nan             nan             nan  \n20       Speaker 1             nan             nan             nan  \n21       Speaker 2             nan             nan             nan  \n22       Speaker 3             nan             nan             nan  \n23       Speaker 1       Speaker 1             nan             nan  \n24       Speaker 4       Speaker 4             nan             nan  \n25             nan       Speaker 4             nan             nan  \n26             nan       Speaker 4             nan             nan  \n27             nan       Speaker 4       Speaker 4             nan  \n28             nan       Speaker 1       Speaker 1             nan  \n29             nan             nan       Speaker 4             nan  \n30             nan             nan       Speaker 4             nan  \n31             nan             nan       Speaker 4       Speaker 4  \n32             nan             nan       Speaker 1       Speaker 1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original</th>\n      <th>strided_chunk_0</th>\n      <th>strided_chunk_1</th>\n      <th>strided_chunk_2</th>\n      <th>strided_chunk_3</th>\n      <th>strided_chunk_4</th>\n      <th>strided_chunk_5</th>\n      <th>strided_chunk_6</th>\n      <th>strided_chunk_7</th>\n      <th>strided_chunk_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>After a few weeks, he didn't see any recovery,...</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>So he said, very likely that I will have to be...</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What goes through your head though, when this ...</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Initially, there was a lot of denial that this...</td>\n      <td>Speaker 3</td>\n      <td>Speaker 3</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>All my friends are riders.</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>All of us have been through accidents, even so...</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>My friend banged his body into a tree and his ...</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>It was quite bad.</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>But after a few months, he still managed to re...</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>So how long did it take for you to be discharg...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>I was in hospital for a total of about six mon...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Months?</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 2</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>One month in the ICU, one month in high depend...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>and then just one month in a normal ward befor...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Actually, what is physiotherapy?</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Just exercises.</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 3</td>\n      <td>Speaker 3</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Because I still have my deltoids and my biceps,</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 2</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>but my triceps are paralysed and I have only w...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>So I can move my wrist this way, but if I flip...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>No way!</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Wow!</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Oh, I see, I see.</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 2</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Oh!</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 3</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>So in terms of what you can do with your limbs...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>What can I do?</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Right now, I can push my own chair, but not ve...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>It's like maybe on a flat surface, it's fine.</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Once there's a bit of a slope or unevenness, t...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>So you can use your hands, it's just that the ...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>Speaker 1</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>I can use my arms, but my fingers are paralysed.</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>So I can't really pick things up.</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Like if I drop my phone on the floor, I can't ...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 4</td>\n      <td>Speaker 4</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Oh!</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>Speaker 1</td>\n      <td>Speaker 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_with_stride_and_indices(initial_list: list, stride: int, number_of_chunks: int):\n",
    "    stride -= 1\n",
    "    N = len(initial_list)\n",
    "\n",
    "    # Calculate base chunk size without considering stride for simplicity\n",
    "    base_chunk_size = (N + number_of_chunks - 1) // number_of_chunks\n",
    "\n",
    "    # Prepare initial chunks without stride\n",
    "    initial_chunks = [initial_list[i * base_chunk_size:(i + 1) * base_chunk_size] for i in range(number_of_chunks)]\n",
    "    initial_chunk_indices = [list(range(i * base_chunk_size, min((i + 1) * base_chunk_size, N))) for i in range(number_of_chunks)]\n",
    "\n",
    "    stride_chunks = []\n",
    "    stride_chunk_indices = []\n",
    "\n",
    "    for i in range(number_of_chunks):\n",
    "        # Calculate the effective start and end, incorporating stride where applicable\n",
    "        start = max(0, i * base_chunk_size - stride)\n",
    "        end = min(N, (i + 1) * base_chunk_size + stride if i < number_of_chunks - 1 else N)\n",
    "\n",
    "        # Slice the original list and indices accordingly\n",
    "        current_chunk = initial_list[start:end]\n",
    "        current_indices = list(range(start, end))\n",
    "\n",
    "        stride_chunks.append(current_chunk)\n",
    "        stride_chunk_indices.append(current_indices)\n",
    "\n",
    "    return stride_chunks, stride_chunk_indices\n",
    "\n",
    "strided_chunks, strided_chunk_indices = chunk_with_stride_and_indices(per_line, STRIDE, NUMBER_OF_CHUNKS)\n",
    "\n",
    "# Remove empty lists\n",
    "strided_chunk_indices = [ele for ele in strided_chunk_indices if ele != []]\n",
    "strided_chunks = [ele for ele in strided_chunks if ele != []]\n",
    "\n",
    "# Assuming 'per_line' and 'strided_chunk_indices' are defined elsewhere in the script\n",
    "comparison_df = pd.DataFrame({'original': per_line})\n",
    "\n",
    "# Use numpy to efficiently calculate the min and max values for DataFrame index\n",
    "min_val = np.min([min(sublist) for sublist in strided_chunk_indices])\n",
    "max_val = np.max([max(sublist) for sublist in strided_chunk_indices])\n",
    "\n",
    "# Initialize the DataFrame with the correct index range\n",
    "strided_chunk_df = pd.DataFrame(index=np.arange(min_val, max_val + 1))\n",
    "\n",
    "# Populate the DataFrame with strided chunk data\n",
    "for i, sublist in enumerate(strided_chunk_indices):\n",
    "    # Direct assignment to the DataFrame using loc for precise index matching\n",
    "    strided_chunk_df.loc[sublist, f'strided_chunk_{i}'] = strided_chunks[i]\n",
    "\n",
    "# Combine the initial comparison DataFrame with the newly created strided chunk DataFrame\n",
    "combined_df = pd.concat([comparison_df, strided_chunk_df], axis=1)\n",
    "\n",
    "class TextDiarizer:\n",
    "    def __init__(self, client, deployment):\n",
    "        self.client = client\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def diarize_chunk(self, sentences, prev_labels_info=None):\n",
    "        \"\"\"Diarize a chunk of text, optionally using information from previous labels.\"\"\"\n",
    "        system_message = \"You are a linguistics expert with 100 years of experience. You will be given a transcription of a meeting between 4 people, and you are to assign the Speaker label to each sentence PER line. I.e. Given the prompt, you will return me: ['Speaker 1', 'Speaker 2', 'Speaker 2']. There is a possibility that a speaker may speak for more than 1 line at time. You will DO YOUR JOB WELL.\"\n",
    "\n",
    "        if prev_labels_info:\n",
    "            prev_speaker_labels = list(prev_labels_info.values())\n",
    "            sentences_dict = prev_speaker_labels[0]\n",
    "            speaker_labels_dict = prev_speaker_labels[1]\n",
    "\n",
    "            # creating {'sentence':speaker_label} dictionary\n",
    "            sentence_speaker_mapping = {value: speaker_labels_dict[key] for key, value in sentences_dict.items()}\n",
    "\n",
    "            user_message = f\"Here are the previous exchanges RIGHT before this followed by their respective speaker(s):\\n{sentence_speaker_mapping} \\n Here is the list of sentences:\\n{sentences}\\nNote that this contains the previous exchanges as well. I MUST RECEIVE ALL {len(sentences)} exchanges. JUST RETURN ME THE LIST.\"\n",
    "        else:\n",
    "            user_message = f\"Here is the list of sentences: \\n{sentences}. \\nThere are {len(sentences)} exchanges. You will diarize ALL the sentences in the list. You WILL ensure that you label ALL {len(sentences)} lines. JUST RETURN ME THE LIST.\"\n",
    "        print('user message:', user_message + '\\n\\n')\n",
    "        diarization = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=2500,\n",
    "            stream=False,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return ast.literal_eval(diarization.choices[0].message.content)\n",
    "\n",
    "    def get_stride_info(self, chunk_df, total_label_list, chunk_number, stride):\n",
    "        \"\"\"Retrieve and label the information for a given stride.\"\"\"\n",
    "        column_name = f'strided_chunk_{chunk_number}'\n",
    "        chunk_df[column_name] = chunk_df[column_name].replace('nan', np.nan)\n",
    "\n",
    "        _ = chunk_df[column_name].dropna()\n",
    "        stride_df = pd.DataFrame(_.tail(stride))\n",
    "        previous_speaker_labels = total_label_list[-1][-stride:]\n",
    "        stride_df['speaker_labels'] = previous_speaker_labels\n",
    "        return stride_df.to_dict()\n",
    "\n",
    "    def label_aware(self, stride, number_of_chunks, combined_chunk_df):\n",
    "        total_label_list = []\n",
    "\n",
    "        # Process the first chunk\n",
    "        combined_chunk_df['strided_chunk_0'] = combined_chunk_df['strided_chunk_0'].replace('nan', np.nan)\n",
    "        first_chunk = combined_chunk_df['strided_chunk_0'].dropna().tolist()\n",
    "        speaker_labels = self.diarize_chunk(first_chunk)\n",
    "        total_label_list.append(speaker_labels)\n",
    "\n",
    "        # Process subsequent chunks\n",
    "        for chunk_number in range(1, (len(combined_chunk_df.columns) - 1)):\n",
    "            column_name = f'strided_chunk_{chunk_number}'\n",
    "            combined_chunk_df[column_name] = combined_chunk_df[column_name].replace('nan', np.nan)\n",
    "            current_chunk = combined_chunk_df[column_name].dropna(how='any').tolist()\n",
    "            prev_labels_info = self.get_stride_info(combined_chunk_df, total_label_list, chunk_number - 1, stride)\n",
    "            speaker_labels = self.diarize_chunk(current_chunk, prev_labels_info)\n",
    "            total_label_list.append(speaker_labels)\n",
    "\n",
    "        return total_label_list\n",
    "\n",
    "diarizer = TextDiarizer(client, DEPLOYMENT)\n",
    "final_labels = diarizer.label_aware(STRIDE, NUMBER_OF_CHUNKS, combined_df)\n",
    "print(final_labels)\n",
    "\n",
    "def final_df(per_line, strided_chunk_indices, final_labels):\n",
    "    # Assuming 'per_line' and 'strided_chunk_indices' are defined elsewhere in the script\n",
    "    label_comparison_df = pd.DataFrame({'original': per_line})\n",
    "\n",
    "    # Use numpy to efficiently calculate the min and max values for DataFrame index\n",
    "    min_val = np.min([min(sublist) for sublist in strided_chunk_indices])\n",
    "    max_val = np.max([max(sublist) for sublist in strided_chunk_indices])\n",
    "\n",
    "    # Initialize the DataFrame with the correct index range\n",
    "    label_strided_chunk_df = pd.DataFrame(index=np.arange(min_val, max_val + 1))\n",
    "\n",
    "    # Populate the DataFrame with strided chunk data\n",
    "    for i, sublist in enumerate(strided_chunk_indices):\n",
    "        # Direct assignment to the DataFrame using loc for precise index matching\n",
    "        label_strided_chunk_df.loc[sublist, f'strided_chunk_{i}'] = final_labels[i]\n",
    "\n",
    "    # Combine the initial comparison DataFrame with the newly created strided chunk DataFrame\n",
    "    combined_label_df = pd.concat([label_comparison_df, label_strided_chunk_df], axis=1)\n",
    "    return combined_label_df\n",
    "\n",
    "final_label_df = final_df(per_line, strided_chunk_indices, final_labels)\n",
    "final_label_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:12:43.088137Z",
     "start_time": "2024-07-05T16:10:34.168088Z"
    }
   },
   "id": "fde3c9b1e5da7ddc",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Storing Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b21fffb5ef137a80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:12:44.696434Z",
     "start_time": "2024-07-05T16:12:43.090012Z"
    }
   },
   "id": "f90791dae585d786",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DF_FILE_NAME = './final_labels/'+file_name+'.h5'\n",
    "store = pd.HDFStore(DF_FILE_NAME)\n",
    "store['df'] = final_label_df  # save it"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:12:44.712103Z",
     "start_time": "2024-07-05T16:12:44.697418Z"
    }
   },
   "id": "d1162cf7c05d0113",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Diarization at an utterance level"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c607774dd9a214c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found only 3 clusters. Using a smaller value than 12 for `min_cluster_size` might help.\n",
      "start=0.0s stop=5.1s speaker_SPEAKER_00\n",
      "start=5.5s stop=6.9s speaker_SPEAKER_00\n",
      "start=7.5s stop=7.9s speaker_SPEAKER_00\n",
      "start=8.0s stop=10.4s speaker_SPEAKER_00\n",
      "start=10.8s stop=13.2s speaker_SPEAKER_00\n",
      "start=13.4s stop=16.3s speaker_SPEAKER_02\n",
      "start=16.3s stop=37.6s speaker_SPEAKER_00\n",
      "start=17.0s stop=17.3s speaker_SPEAKER_02\n",
      "start=26.0s stop=26.5s speaker_SPEAKER_02\n",
      "start=33.0s stop=34.2s speaker_SPEAKER_02\n",
      "start=37.6s stop=37.8s speaker_SPEAKER_02\n",
      "start=37.8s stop=46.1s speaker_SPEAKER_00\n",
      "start=37.8s stop=38.2s speaker_SPEAKER_02\n",
      "start=38.2s stop=38.3s speaker_SPEAKER_01\n",
      "start=38.3s stop=38.3s speaker_SPEAKER_02\n",
      "start=38.3s stop=38.3s speaker_SPEAKER_01\n",
      "start=46.1s stop=53.3s speaker_SPEAKER_00\n",
      "start=46.2s stop=46.2s speaker_SPEAKER_01\n",
      "start=46.3s stop=46.9s speaker_SPEAKER_01\n",
      "start=53.6s stop=56.5s speaker_SPEAKER_00\n",
      "start=57.1s stop=62.9s speaker_SPEAKER_02\n",
      "start=59.9s stop=60.2s speaker_SPEAKER_00\n",
      "start=63.1s stop=64.7s speaker_SPEAKER_00\n",
      "start=64.9s stop=82.0s speaker_SPEAKER_00\n",
      "start=80.7s stop=80.8s speaker_SPEAKER_01\n",
      "start=80.8s stop=83.0s speaker_SPEAKER_02\n",
      "start=83.0s stop=83.0s speaker_SPEAKER_00\n",
      "start=83.0s stop=83.1s speaker_SPEAKER_02\n",
      "start=83.1s stop=89.9s speaker_SPEAKER_01\n",
      "start=90.3s stop=92.1s speaker_SPEAKER_00\n",
      "start=92.4s stop=115.0s speaker_SPEAKER_00\n",
      "start=101.4s stop=102.0s speaker_SPEAKER_01\n",
      "start=105.5s stop=105.9s speaker_SPEAKER_01\n",
      "start=105.9s stop=106.0s speaker_SPEAKER_01\n",
      "start=110.2s stop=110.8s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",use_auth_token='')\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(audio_file,num_speakers=4)\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0\n",
    "# ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T15:58:39.526520Z",
     "start_time": "2024-07-05T15:55:25.404613Z"
    }
   },
   "id": "d1d591cbbb04f58d",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
