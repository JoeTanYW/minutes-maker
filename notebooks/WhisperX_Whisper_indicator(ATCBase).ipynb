{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install WhisperX\n",
        "!pip install git+https://github.com/m-bain/whisperx.git --quiet\n",
        "\n",
        "# Install additional required libraries\n",
        "!pip install moviepy pydub --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbBYYB-1mPoS",
        "outputId": "9132882f-ecdc-4a5b-8b68-d219fde1f708"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m176.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m817.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m128.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m158.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for whisperx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa --quiet\n",
        "!pip install praat-parselmouth --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Va0PmFktk3",
        "outputId": "5c458ce5-a45d-4ef7-ac6f-692a7f303b3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/10.7 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m194.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QcaaNxdAkhV2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import whisperx\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from pydub import AudioSegment\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "from moviepy.editor import VideoFileClip\n",
        "from scipy import signal\n",
        "from scipy.signal import find_peaks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and set up authentication\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBS3GcnmkkIb",
        "outputId": "1cccc656-10f2-43bb-8d0d-6cb88c7929e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear GPU memory\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "BEkIjgGs46YY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files_in_folder(folder_name):\n",
        "    query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder'\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    folder = results.get('files', [])[0]\n",
        "\n",
        "    query = f\"'{folder['id']}' in parents\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get('files', [])\n",
        "\n",
        "    return files\n",
        "\n",
        "def download_file(file_id, file_name):\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    fh = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "\n",
        "    fh.seek(0)\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(fh.read())\n",
        "    print(f\"Downloaded: {file_name}\")\n",
        "\n",
        "def perform_diarization(audio_path, min_speakers=2, max_speakers=3):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    audio = whisperx.load_audio(audio_path)\n",
        "\n",
        "    diarize_model = whisperx.DiarizationPipeline(\n",
        "        use_auth_token=\"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\",\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    diarize_segments = diarize_model(\n",
        "        audio,\n",
        "        min_speakers=min_speakers,\n",
        "        max_speakers=max_speakers\n",
        "    )\n",
        "\n",
        "    return diarize_segments\n",
        "\n",
        "def extract_pitch(audio, sr):\n",
        "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
        "    pitch = np.mean(pitches[magnitudes > np.max(magnitudes)*0.7])\n",
        "    return pitch\n",
        "\n",
        "def extract_spectral_tilt(audio, sr):\n",
        "    # Compute the short-time Fourier transform\n",
        "    S = librosa.stft(audio)\n",
        "\n",
        "    # Compute the power spectrum\n",
        "    power_spectrum = np.abs(S)**2\n",
        "\n",
        "    # Compute the spectral tilt (slope of the spectrum in dB)\n",
        "    freq_bins = librosa.fft_frequencies(sr=sr)\n",
        "    log_power_spectrum = librosa.amplitude_to_db(power_spectrum)\n",
        "    spectral_tilt = np.polyfit(freq_bins, np.mean(log_power_spectrum, axis=1), deg=1)[0]\n",
        "\n",
        "    return spectral_tilt\n",
        "\n",
        "def extract_timbre(audio, sr):\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    return np.mean(spectral_centroids)\n",
        "\n",
        "def transcribe_segment(audio_segment, processor, model, device):\n",
        "    input_features = processor(audio_segment, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
        "    predicted_ids = model.generate(input_features)\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "    return transcription[0]\n",
        "\n",
        "def transcribe_and_align(audio_path, diarize_segments):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load model and processor\n",
        "    processor = WhisperProcessor.from_pretrained(\"jlvdoorn/whisper-large-v3-atco2-asr\")\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\"jlvdoorn/whisper-large-v3-atco2-asr\").to(device)\n",
        "\n",
        "    # Load full audio\n",
        "    audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "    # Convert diarize_segments to DataFrame if it's not already\n",
        "    if not isinstance(diarize_segments, pd.DataFrame):\n",
        "        diarize_segments = pd.DataFrame(diarize_segments)\n",
        "\n",
        "    print(\"Diarization segments structure:\")\n",
        "    print(diarize_segments.head())\n",
        "    print(diarize_segments.columns)\n",
        "\n",
        "    # Process each segment\n",
        "    results = []\n",
        "\n",
        "    for _, segment in diarize_segments.iterrows():\n",
        "        start_sample = int(segment['start'] * sr)\n",
        "        end_sample = int(segment['end'] * sr)\n",
        "        audio_segment = audio[start_sample:end_sample]\n",
        "\n",
        "        transcription = transcribe_segment(audio_segment, processor, model, device)\n",
        "\n",
        "        # Extract features\n",
        "        pitch = extract_pitch(audio_segment, sr)\n",
        "        spectral_tilt = extract_spectral_tilt(audio_segment, sr)\n",
        "        timbre = extract_timbre(audio_segment, sr)\n",
        "\n",
        "        results.append({\n",
        "            \"start\": segment['start'],\n",
        "            \"end\": segment['end'],\n",
        "            \"speaker\": segment['speaker'],\n",
        "            \"text\": transcription,\n",
        "            \"pitch\": pitch,\n",
        "            \"spectral_tilt\": spectral_tilt,\n",
        "            \"timbre\": timbre\n",
        "        })\n",
        "\n",
        "    # Calculate overall ranges for relative scaling\n",
        "    pitches = [r['pitch'] for r in results]\n",
        "    tilts = [r['spectral_tilt'] for r in results]\n",
        "    timbres = [r['timbre'] for r in results]\n",
        "\n",
        "    pitch_min, pitch_max = min(pitches), max(pitches)\n",
        "    tilt_min, tilt_max = min(tilts), max(tilts)\n",
        "    timbre_min, timbre_max = min(timbres), max(timbres)\n",
        "\n",
        "    # Add relative scales\n",
        "    for r in results:\n",
        "        r['pitch_relative'] = (r['pitch'] - pitch_min) / (pitch_max - pitch_min) if pitch_max > pitch_min else 0\n",
        "        r['tilt_relative'] = (r['spectral_tilt'] - tilt_min) / (tilt_max - tilt_min) if tilt_max > tilt_min else 0\n",
        "        r['timbre_relative'] = (r['timbre'] - timbre_min) / (timbre_max - timbre_min) if timbre_max > timbre_min else 0\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_time(seconds):\n",
        "    return str(timedelta(seconds=seconds)).split('.')[0]\n",
        "\n",
        "def process_transcription_output(segments):\n",
        "    formatted_output = \"Air Traffic Control Transcription\\n\\n\"\n",
        "\n",
        "    for segment in segments:\n",
        "        start_time = format_time(segment['start'])\n",
        "        end_time = format_time(segment['end'])\n",
        "        text = segment['text'].strip()\n",
        "        speaker = segment['speaker']\n",
        "\n",
        "        formatted_output += f\"{speaker} ({start_time} - {end_time}): Text: {text}\\n\"\n",
        "        formatted_output += f\"Pitch: {segment['pitch']:.2f} Hz [{segment['pitch_relative']:.2f}]\\n\"\n",
        "        formatted_output += f\"Spectral Tilt: {segment['spectral_tilt']:.2f} [{segment['tilt_relative']:.2f}]\\n\"\n",
        "        formatted_output += f\"Timbre: {segment['timbre']:.2f} [{segment['timbre_relative']:.2f}]\\n\\n\"\n",
        "\n",
        "    return formatted_output\n",
        "\n",
        "# Main execution\n",
        "files = list_files_in_folder(\"diary\")\n",
        "\n",
        "print(\"Available files in the 'diary' folder:\")\n",
        "for i, file in enumerate(files):\n",
        "    print(f\"{i + 1}. {file['name']}\")\n",
        "\n",
        "selection = int(input(\"Enter the number of the file you want to process: \")) - 1\n",
        "selected_file = files[selection]\n",
        "\n",
        "download_file(selected_file['id'], selected_file['name'])\n",
        "\n",
        "print(\"Performing speaker diarization...\")\n",
        "diarize_segments = perform_diarization(selected_file['name'])\n",
        "\n",
        "print(\"Diarization segments:\")\n",
        "print(diarize_segments)\n",
        "\n",
        "print(\"Transcribing audio and aligning with diarization...\")\n",
        "result = transcribe_and_align(selected_file['name'], diarize_segments)\n",
        "\n",
        "formatted_output = process_transcription_output(result)\n",
        "\n",
        "output_filename = 'transcription_output.txt'\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    f.write(formatted_output)\n",
        "\n",
        "print(f\"Transcription and speaker features have been saved to '{output_filename}'\")\n",
        "\n",
        "os.remove(selected_file['name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8LokGF7rPNp",
        "outputId": "e9134d3c-aeb7-4185-f6d3-8ee66ce8e226"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available files in the 'diary' folder:\n",
            "1. Draft N4490R.mp4\n",
            "2. Raid Meeting.mp4\n",
            "3. Raid Meeting.m4a\n",
            "4. N8350D.mp4\n",
            "5. EP15.mp4\n",
            "6. EP14.mp4\n",
            "7. EP11.mp4\n",
            "8. EP8.mp4\n",
            "9. EP19.mp4\n",
            "10. EP17.mp4\n",
            "11. EP10.mp4\n",
            "12. EP21.mp4\n",
            "13. EP4.mp4\n",
            "14. EP22.mp4\n",
            "15. EP23.mp4\n",
            "Enter the number of the file you want to process: 1\n",
            "Downloaded: Draft N4490R.mp4\n",
            "Performing speaker diarization...\n",
            "Diarization segments:\n",
            "                              segment label     speaker       start  \\\n",
            "0   [ 00:00:10.398 -->  00:00:18.531]     A  SPEAKER_00   10.398981   \n",
            "1   [ 00:00:23.047 -->  00:00:30.670]     B  SPEAKER_00   23.047538   \n",
            "2   [ 00:00:36.273 -->  00:00:37.139]     C  SPEAKER_00   36.273345   \n",
            "3   [ 00:00:40.415 -->  00:00:41.196]     D  SPEAKER_00   40.415959   \n",
            "4   [ 00:00:41.604 -->  00:00:42.368]     E  SPEAKER_00   41.604414   \n",
            "5   [ 00:00:43.913 -->  00:00:46.799]     F  SPEAKER_00   43.913413   \n",
            "6   [ 00:00:45.814 -->  00:00:46.120]     G  SPEAKER_01   45.814941   \n",
            "7   [ 00:00:46.952 -->  00:00:47.512]     H  SPEAKER_00   46.952462   \n",
            "8   [ 00:00:49.957 -->  00:00:51.434]     I  SPEAKER_00   49.957555   \n",
            "9   [ 00:00:53.794 -->  00:00:59.668]     J  SPEAKER_00   53.794567   \n",
            "10  [ 00:00:59.889 -->  00:01:00.959]     K  SPEAKER_00   59.889643   \n",
            "11  [ 00:01:08.463 -->  00:01:14.490]     L  SPEAKER_00   68.463497   \n",
            "12  [ 00:01:21.977 -->  00:01:25.458]     M  SPEAKER_00   81.977929   \n",
            "13  [ 00:01:26.477 -->  00:01:28.344]     N  SPEAKER_00   86.477080   \n",
            "14  [ 00:01:35.764 -->  00:01:37.580]     O  SPEAKER_00   95.764007   \n",
            "15  [ 00:01:40.144 -->  00:01:41.689]     P  SPEAKER_02  100.144312   \n",
            "16  [ 00:01:42.470 -->  00:01:43.013]     Q  SPEAKER_02  102.470289   \n",
            "17  [ 00:01:44.320 -->  00:01:44.711]     R  SPEAKER_02  104.320883   \n",
            "18  [ 00:01:48.887 -->  00:01:53.285]     S  SPEAKER_02  108.887946   \n",
            "19  [ 00:01:56.154 -->  00:02:00.331]     T  SPEAKER_01  116.154499   \n",
            "20  [ 00:02:00.789 -->  00:02:02.249]     U  SPEAKER_01  120.789474   \n",
            "21  [ 00:02:04.966 -->  00:02:06.375]     V  SPEAKER_02  124.966044   \n",
            "22  [ 00:02:07.563 -->  00:02:08.735]     W  SPEAKER_01  127.563667   \n",
            "23  [ 00:02:08.837 -->  00:02:12.045]     X  SPEAKER_01  128.837012   \n",
            "24  [ 00:02:12.741 -->  00:02:16.103]     Y  SPEAKER_01  132.741935   \n",
            "25  [ 00:02:16.103 -->  00:02:16.137]     Z  SPEAKER_00  136.103565   \n",
            "26  [ 00:02:17.393 -->  00:02:18.005]    AA  SPEAKER_02  137.393888   \n",
            "27  [ 00:02:18.005 -->  00:02:18.769]    AB  SPEAKER_00  138.005093   \n",
            "28  [ 00:02:27.750 -->  00:02:29.804]    AC  SPEAKER_00  147.750424   \n",
            "29  [ 00:02:33.370 -->  00:02:34.643]    AD  SPEAKER_00  153.370119   \n",
            "30  [ 00:02:35.662 -->  00:02:37.003]    AE  SPEAKER_00  155.662139   \n",
            "31  [ 00:02:37.003 -->  00:02:39.533]    AF  SPEAKER_02  157.003396   \n",
            "32  [ 00:02:41.061 -->  00:02:42.385]    AG  SPEAKER_01  161.061121   \n",
            "33  [ 00:02:43.438 -->  00:02:45.220]    AH  SPEAKER_00  163.438031   \n",
            "34  [ 00:02:46.086 -->  00:02:46.986]    AI  SPEAKER_00  166.086587   \n",
            "\n",
            "           end  \n",
            "0    18.531409  \n",
            "1    30.670628  \n",
            "2    37.139219  \n",
            "3    41.196944  \n",
            "4    42.368421  \n",
            "5    46.799660  \n",
            "6    46.120543  \n",
            "7    47.512733  \n",
            "8    51.434635  \n",
            "9    59.668930  \n",
            "10   60.959253  \n",
            "11   74.490662  \n",
            "12   85.458404  \n",
            "13   88.344652  \n",
            "14   97.580645  \n",
            "15  101.689304  \n",
            "16  103.013582  \n",
            "17  104.711375  \n",
            "18  113.285229  \n",
            "19  120.331070  \n",
            "20  122.249576  \n",
            "21  126.375212  \n",
            "22  128.735144  \n",
            "23  132.045840  \n",
            "24  136.103565  \n",
            "25  136.137521  \n",
            "26  138.005093  \n",
            "27  138.769100  \n",
            "28  149.804754  \n",
            "29  154.643463  \n",
            "30  157.003396  \n",
            "31  159.533107  \n",
            "32  162.385399  \n",
            "33  165.220713  \n",
            "34  166.986418  \n",
            "Transcribing audio and aligning with diarization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diarization segments structure:\n",
            "                             segment label     speaker      start        end\n",
            "0  [ 00:00:10.398 -->  00:00:18.531]     A  SPEAKER_00  10.398981  18.531409\n",
            "1  [ 00:00:23.047 -->  00:00:30.670]     B  SPEAKER_00  23.047538  30.670628\n",
            "2  [ 00:00:36.273 -->  00:00:37.139]     C  SPEAKER_00  36.273345  37.139219\n",
            "3  [ 00:00:40.415 -->  00:00:41.196]     D  SPEAKER_00  40.415959  41.196944\n",
            "4  [ 00:00:41.604 -->  00:00:42.368]     E  SPEAKER_00  41.604414  42.368421\n",
            "Index(['segment', 'label', 'speaker', 'start', 'end'], dtype='object')\n",
            "Transcription and speaker features have been saved to 'transcription_output.txt'\n"
          ]
        }
      ]
    }
  ]
}